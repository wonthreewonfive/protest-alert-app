# app.py
import streamlit as st
import pandas as pd
import pydeck as pdk
import altair as alt
from dateutil import parser
from datetime import date, datetime
from streamlit_calendar import calendar
from pathlib import Path
import re
import textwrap
from collections import Counter

# --- optional: wordcloud ---
try:
    from wordcloud import WordCloud
    WORDCLOUD_AVAILABLE = True
except Exception:
    WORDCLOUD_AVAILABLE = False

st.set_page_config(page_title="ì§‘íšŒ/ì‹œìœ„ ì•Œë¦¼ ì„œë¹„ìŠ¤", page_icon="ğŸ“…", layout="wide")

# ===== ìŠ¤íƒ€ì¼ =====
st.markdown("""
<style>
  .stApp, .main, [data-testid="stHeader"] { background: #ffffff !important; }

  /* ìƒë‹¨ ì‚¬ì´íŠ¸ íƒ€ì´í‹€ í—¤ë” */
  .app-header{
    border:1px solid #e5e7eb; border-radius:12px;
    background:#f3f4f6; padding:14px 24px;
    font-weight:800; font-size:20px; color:#111827;
    text-align:center; margin:6px 0 16px 0;
  }

  /* ì¹´ë“œ ê³µí†µ */
  .card { border:1px solid #e5e7eb; border-radius:14px; padding:16px; margin:12px 6px; background:#fff; }
  .time { font-weight:800; font-size:18px; margin-bottom:6px; color:#111827; }
  .sub  { color:#6b7280; font-size:14px; margin-bottom:8px; }
  .meta { color:#374151; font-size:14px; }

  /* ì¹´ë“œí˜• ë§í¬ */
  a.card-link { display:block; text-decoration:none; color:inherit; }
  a.card-link .card:hover { border-color:#94a3b8; background:#f8fafc; }

  /* ë‹¬ë ¥: í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³  ë„íŠ¸ë§Œ ë³´ì´ê²Œ */
  .fc .fc-daygrid-dot-event .fc-event-time,
  .fc .fc-daygrid-dot-event .fc-event-title,
  .fc .fc-daygrid-event-harness .fc-event-time,
  .fc .fc-daygrid-event-harness .fc-event-title { display:none !important; }
  .fc-daygrid-dot-event > .fc-event-dot { width:10px; height:10px; border:0; }
</style>
""", unsafe_allow_html=True)

# ---------- ë°ì´í„° ë¡œë“œ ----------
@st.cache_data
def load_events(path: str) -> pd.DataFrame:
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")

    df = pd.read_excel(p) if p.suffix.lower() in [".xlsx", ".xls"] else pd.read_csv(p)

    variants = {
        "date": ["date","ë‚ ì§œ"],
        "start_time": ["start_time","start","ì‹œì‘","starttime"],
        "end_time": ["end_time","end","ì¢…ë£Œ","endtime"],
        "location": ["location","ì¥ì†Œ","place"],
        "district": ["district","ê´€í• ì„œ","êµ¬"],
        "reported_head": ["reported_head","reported_headcount","ì‹ ê³ ì¸ì›","ì¸ì›"],
        "memo": ["memo","ë¹„ê³ ","ë©”ëª¨"],
    }
    def find_col(k):
        for cand in variants[k]:
            for c in df.columns:
                if str(c).strip().lower() == cand.lower():
                    return c
        return None
    col = {k: find_col(k) for k in variants}
    for k in ["date","start_time","end_time","location"]:
        if col[k] is None: raise ValueError(f"'{k}' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    def to_date(x):
        if pd.isna(x): return None
        s = str(x).strip()
        if re.match(r'^\d{4}\.\d{1,2}\.\d{1,2}$', s):
            s = s.replace(".", "-")
        try: return parser.parse(s).date()
        except: return None

    def to_time(x):
        if pd.isna(x): return None
        try:
            t = parser.parse(str(x)).time()
            return f"{t.hour:02d}:{t.minute:02d}"
        except: return None

    df["_date"]  = df[col["date"]].apply(to_date)
    df["_start"] = df[col["start_time"]].apply(to_time)
    df["_end"]   = df[col["end_time"]].apply(to_time)
    df["_loc"]   = df[col["location"]].astype(str)
    df["_dist"]  = df[col["district"]].astype(str) if col["district"] else ""
    df["_head"]  = df[col["reported_head"]] if col["reported_head"] else ""
    df["_memo"]  = df[col["memo"]].astype(str) if col["memo"] else ""

    df = df[df["_date"].notnull() & df["_start"].notnull() & df["_end"].notnull()]
    return df.reset_index(drop=True)

@st.cache_data
def load_bus(path: str) -> pd.DataFrame:
    """
    bus_data.xlsx
    í•„ìš”í•œ ì»¬ëŸ¼: start_date, start_time, end_date, end_time, ARS_ID, ì •ë¥˜ì†Œëª…, xì¢Œí‘œ(lon), yì¢Œí‘œ(lat)
    """
    p = Path(path)
    if not p.exists():
        return pd.DataFrame()
    df = pd.read_excel(p)

    def to_date(x):
        if pd.isna(x): return None
        s = str(x).strip()
        if re.match(r'^\d{4}\.\d{1,2}\.\d{1,2}$', s):
            s = s.replace(".", "-")
        try: return parser.parse(s).date()
        except: return None

    def to_time(x):
        if pd.isna(x): return None
        try:
            t = parser.parse(str(x)).time()
            return f"{t.hour:02d}:{t.minute:02d}"
        except: return None

    # ìœ ì—° ì»¬ëŸ¼ëª… ë§¤í•‘
    cols = {c: str(c).strip().lower() for c in df.columns}
    def pick(*names):
        for n in names:
            for c, lc in cols.items():
                if lc == n:
                    return c
        return None

    c_sd = pick("start_date","ì‹œì‘ì¼")
    c_st = pick("start_time","ì‹œì‘ì‹œê°„")
    c_ed = pick("end_date","ì¢…ë£Œì¼")
    c_et = pick("end_time","ì¢…ë£Œì‹œê°„")
    c_ars= pick("ars_id","ars","ì •ë¥˜ì¥id")
    c_nm = pick("ì •ë¥˜ì†Œëª…","ì •ë¥˜ì¥ëª…","stop_name")
    c_x  = pick("xì¢Œí‘œ","x","lon","lng")
    c_y  = pick("yì¢Œí‘œ","y","lat")

    req = [c_sd,c_st,c_ed,c_et,c_ars,c_nm,c_x,c_y]
    if any(c is None for c in req):
        return pd.DataFrame()

    # ARS_ID â†’ ìˆ«ì/ì  ì œê±° í›„ 5ìë¦¬ 0-padding
    ars_series = (
        df[c_ars]
        .astype(str)
        .map(lambda s: re.sub(r"\D", "", s))
        .map(lambda s: s.zfill(5))
    )

    out = pd.DataFrame({
        "start_date": df[c_sd].apply(to_date),
        "start_time": df[c_st].apply(to_time),
        "end_date":   df[c_ed].apply(to_date),
        "end_time":   df[c_et].apply(to_time),
        "ARS_ID":     ars_series,
        "ì •ë¥˜ì†Œëª…":      df[c_nm].astype(str),
        "lon":        pd.to_numeric(df[c_x], errors="coerce"),
        "lat":        pd.to_numeric(df[c_y], errors="coerce"),
    })
    out = out.dropna(subset=["start_date","end_date","lon","lat"]).reset_index(drop=True)
    return out

@st.cache_data
def load_routes(path: str) -> pd.DataFrame:
    """
    routes_final.csv (ì˜ˆì‹œ ì»¬ëŸ¼: date, ars_id, route)
    """
    p = Path(path)
    if not p.exists():
        return pd.DataFrame(columns=["date","ars_id","route"])
    df = pd.read_csv(p, dtype={"ars_id": str, "route": str})

    def to_date(x):
        try:
            return parser.parse(str(x)).date()
        except Exception:
            return None

    df["date"] = df["date"].apply(to_date)
    df["ars_id"] = (
        df["ars_id"].astype(str)
        .str.replace(r"\D", "", regex=True)
        .str.zfill(5)
    )
    df["route"] = df["route"].fillna("").astype(str).str.strip()
    return df.dropna(subset=["date","ars_id"]).reset_index(drop=True)

def color_by_headcount(h):
    try:
        n = int(h)
        if n >= 1000: return "#ef4444"
        if n >= 500:  return "#f59e0b"
        return "#3b82f6"
    except:
        return "#3b82f6"

def df_to_month_dots(df: pd.DataFrame):
    events = []
    for _, r in df.iterrows():
        start_iso = f"{r['_date']}T{r['_start']}:00"
        end_iso   = f"{r['_date']}T{r['_end']}:00"
        events.append({
            "title": "",
            "start": start_iso,
            "end": end_iso,
            "display": "list-item",
            "color": color_by_headcount(r["_head"]),
        })
    return events

def filter_by_day(df: pd.DataFrame, d: date) -> pd.DataFrame:
    return df[df["_date"] == d].sort_values(by=["_start","_end","_loc"])

def get_bus_rows_for_date(bus_df: pd.DataFrame, d: date) -> pd.DataFrame:
    if bus_df is None or bus_df.empty:
        return pd.DataFrame()
    m = (bus_df["start_date"] <= d) & (bus_df["end_date"] >= d)
    return bus_df[m].copy()

# -------------- í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬/í‚¤ì›Œë“œ --------------
_STOPWORDS = {
    "ê·¸ë¦¬ê³ ","ê·¸ëŸ¬ë‚˜","í•˜ì§€ë§Œ","ë˜ëŠ”","ë°","ë•Œë¬¸","ë•Œë¬¸ì—","ëŒ€í•œ","ê´€ë ¨","ëŒ€í•´",
    "ì—¬ëŸ¬ë¶„","ì •ë„","ë¶€ë¶„","ë“±","ì¢€","ë„ˆë¬´","ìˆ˜","ê²ƒ","ê±°","ì´ê²ƒ","ì €ê²ƒ","ìš°ë¦¬",
    "ì…ë‹ˆë‹¤","í•©ë‹ˆë‹¤","í•˜ëŠ”","ìˆëŠ”","ë˜ëŠ”","ë©ë‹ˆë‹¤","ë“œë¦½ë‹ˆë‹¤","í•´ì£¼ì‹œë©´","í•´ì£¼ì‹­ì‹œì˜¤",
    "í•´ì£¼ì„¸ìš”","ë¶€íƒë“œë¦½ë‹ˆë‹¤","ê°™ìŠµë‹ˆë‹¤","ê°ì‚¬í•©ë‹ˆë‹¤","ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤","ë¶ˆí¸í•©ë‹ˆë‹¤",
    "ì…ë‹ˆë‹¤ë§Œ","ì•ŠìŠµë‹ˆë‹¤","ì•Šì•„ìš”","ì•Šêµ¬ìš”","ë©ë‹ˆë‹¤ë§Œ",
    "ìœ¼ë¡œ","ë¡œ","ì—ì„œ","ì—ê²Œ","ì—ëŠ”","ì—","ì˜","ì„","ë¥¼","ì´","ê°€","ì™€","ê³¼","ë„","ë§Œ","ë³´ë‹¤",
}
_SUFFIX_PAT = re.compile(
    r"(ì…ë‹ˆë‹¤|í•©ë‹ˆë‹¤|í•˜ì‹­ì‹œì˜¤|í•´ì£¼ì„¸ìš”|í•´ì£¼ì‹œê¸°|í•´ì£¼ì‹œê¸¸|í•´ì£¼ì‹œë©´|í•´ì£¼ì‹­ì‹œì˜¤|"
    r"ë˜ê² ìŠµë‹ˆë‹¤|ë˜ê² ìŠµ|ë˜ì—ˆìŠµ|ë˜ì—ˆìœ¼ë©´|ë˜ë©´|ë˜ì–´|ë˜ì—ˆìŠµë‹ˆë‹¤|ë˜ëŠ”ë°|ì•ŠìŠµë‹ˆë‹¤|ì•Šì•„ìš”|"
    r"ê°™ìŠµë‹ˆë‹¤|í•˜ê² ìŠµë‹ˆë‹¤|ë¶€íƒë“œë¦½ë‹ˆë‹¤|ê°ì‚¬í•©ë‹ˆë‹¤|ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤|í•´ìš”|í–ˆì–´ìš”|í•©ë‹ˆë‹¤ë§Œ)$"
)
def strip_suffix(tok: str) -> str:
    tok = re.sub(_SUFFIX_PAT, "", tok);  return tok
def tokenize_ko(s: str):
    if not isinstance(s, str): return []
    cand = re.findall(r"[ê°€-í£A-Za-z0-9]+", s)
    out = []
    for t in cand:
        t = strip_suffix(t)
        if len(t) < 2:   # í•œ ê¸€ì ì œê±°
            continue
        if t in _STOPWORDS:
            continue
        out.append(t)
    return out
def make_bigrams(tokens, join_str=" "):
    return [join_str.join(pair) for pair in zip(tokens, tokens[1:])]
def build_wordcloud_image(fb_df: pd.DataFrame, date_filter=None, use_bigrams=False,
                          font_path="data/Nanum_Gothic/NanumGothic-Regular.ttf"):
    if not WORDCLOUD_AVAILABLE: return None
    if fb_df is None or fb_df.empty or "feedback" not in fb_df.columns: return None
    df = fb_df.copy()
    if date_filter is not None and "date" in df.columns:
        df = df[df["date"].astype(str) == str(date_filter)]
    texts = df["feedback"].dropna().astype(str).tolist()
    if not texts: return None
    counter = Counter()
    for t in texts:
        toks = tokenize_ko(t)
        if use_bigrams:
            toks = make_bigrams(toks)
        counter.update(toks)
    if not counter: return None
    fp = font_path if Path(font_path).exists() else None
    wc = WordCloud(font_path=fp, width=1200, height=600, background_color="white", colormap="tab20c")
    return wc.generate_from_frequencies(counter).to_image()
def top_terms_from_feedback(fb_df, date_filter=None, use_bigrams=False, top_k=20):
    if fb_df is None or fb_df.empty or "feedback" not in fb_df.columns:
        return pd.DataFrame(columns=["term","count","pct"])
    df = fb_df.copy()
    if date_filter is not None and "date" in df.columns:
        df = df[df["date"].astype(str) == str(date_filter)]
    texts = df["feedback"].dropna().astype(str).tolist()
    if not texts:
        return pd.DataFrame(columns=["term","count","pct"])
    counter = Counter()
    for t in texts:
        toks = tokenize_ko(t)
        if use_bigrams:
            toks = make_bigrams(toks)
        counter.update(toks)
    if not counter:
        return pd.DataFrame(columns=["term","count","pct"])
    items = counter.most_common(top_k)
    out = pd.DataFrame(items, columns=["term","count"])
    out["pct"] = (out["count"] / counter.total() * 100).round(1)
    return out
def load_feedback(path="data/feedback.csv"):
    p = Path(path)
    if not p.exists():
        return pd.DataFrame()
    try:
        return pd.read_csv(p)
    except Exception:
        return pd.DataFrame()

# ---------- ìƒì„¸ í˜ì´ì§€ ----------
def render_detail(df_all: pd.DataFrame, bus_df: pd.DataFrame, routes_df: pd.DataFrame, d: date, idx: int):
    day_df = filter_by_day(df_all, d)
    if len(day_df) == 0 or idx < 0 or idx >= len(day_df):
        st.error("ìƒì„¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.")
        if st.button("â† ëª©ë¡ìœ¼ë¡œ"):
            st.query_params.clear()
            st.rerun()
        return

    row = day_df.iloc[idx]

    WEEK_KO = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]
    st.markdown(f"## {d.month}ì›” {d.day}ì¼({WEEK_KO[d.weekday()]}) ìƒì„¸ ì •ë³´")
    if st.button("â† ëª©ë¡ìœ¼ë¡œ"):
        st.query_params.clear()
        st.rerun()

    # (1) ì˜¤ëŠ˜ì˜ ì§‘íšŒ/ì‹œìœ„
    st.subheader("ì˜¤ëŠ˜ì˜ ì§‘íšŒ/ì‹œìœ„")
    time_str = f"{row['_start']} ~ {row['_end']}"
    loc_str  = f"{(row['_dist']+' ') if row['_dist'] not in ['','nan','None'] else ''}{row['_loc']}"
    if pd.notna(row["_head"]) and str(row["_head"]).strip() != "":
        try: head_str = f"{int(row['_head'])}ëª…"
        except: head_str = f"{row['_head']}ëª…"
    else:
        head_str = ""
    keywords = str(row["_memo"]).strip() if str(row["_memo"]).strip() not in ["nan","None"] else ""
    info_df = pd.DataFrame([[time_str, loc_str, head_str, keywords]],
                           columns=["ì§‘íšŒ ì‹œê°„","ì§‘íšŒ ì¥ì†Œ(í–‰ì§„ë¡œ)","ì‹ ê³  ì¸ì›","ê´€ë ¨ ì´ìŠˆ"])
    st.table(info_df)

    # (1-1) ë²„ìŠ¤ ìš°íšŒ ì •ë³´ + ì§€ë„ (+ë…¸ì„ )
    st.markdown("### ë²„ìŠ¤ ìš°íšŒ ì •ë³´")
    bus_rows = get_bus_rows_for_date(bus_df, d)

    # routes_final.csv ì™€ ê²°í•© (ê°™ì€ ë‚ ì§œ d, ê°™ì€ ì •ë¥˜ì¥ ARS_ID)
    route_slice = pd.DataFrame()
    if routes_df is not None and not routes_df.empty:
        route_slice = routes_df[routes_df["date"] == d].copy()

    if bus_rows.empty:
        st.caption("â€» í•´ë‹¹ ë‚ ì§œì˜ ë²„ìŠ¤ ìš°íšŒ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if not route_slice.empty:
            # ì •ë¥˜ì¥ë³„ ë…¸ì„  ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            agg = (route_slice
                   .dropna(subset=["ars_id","route"])
                   .groupby("ars_id")["route"]
                   .apply(lambda s: ", ".join(sorted(set(s))))
                   .rename("ë…¸ì„ "))
            bus_rows = bus_rows.merge(agg, left_on="ARS_ID", right_index=True, how="left")
        else:
            bus_rows["ë…¸ì„ "] = ""

        # í‘œ
        bus_view = bus_rows[["start_time","end_time","ARS_ID","ì •ë¥˜ì†Œëª…","ë…¸ì„ "]].rename(
            columns={"start_time":"ì‹œì‘ ì‹œê°„","end_time":"ì¢…ë£Œ ì‹œê°„","ARS_ID":"ë²„ìŠ¤ ì •ë¥˜ì†Œ ë²ˆí˜¸","ì •ë¥˜ì†Œëª…":"ë²„ìŠ¤ ì •ë¥˜ì†Œ ëª…"}
        )
        st.table(bus_view.reset_index(drop=True))

        # ì§€ë„: ë§ˆì»¤ + ì •ë¥˜ì†Œ ë²ˆí˜¸ + (íˆ´íŒì— ë…¸ì„ )
        map_df = bus_rows[["lat","lon","ì •ë¥˜ì†Œëª…","ARS_ID","ë…¸ì„ "]].copy()
        if not map_df.empty:
            view_state = pdk.ViewState(
                latitude=float(map_df["lat"].mean()),
                longitude=float(map_df["lon"].mean()),
                zoom=16
            )
            point_layer = pdk.Layer(
                "ScatterplotLayer",
                data=map_df,
                get_position='[lon, lat]',
                get_radius=25,
                get_fill_color=[0, 122, 255, 200],
                pickable=True,
            )
            text_layer = pdk.Layer(
                "TextLayer",
                data=map_df,
                get_position='[lon, lat]',
                get_text="ARS_ID",
                get_color=[0, 0, 0, 255],
                get_size=16,
                get_angle=0,
                get_alignment_baseline='"top"',
                get_pixel_offset=[0, -18],
                billboard=True,
            )
            tooltip = {
                "html": "<b>{ì •ë¥˜ì†Œëª…}</b><br/>ì •ë¥˜ì†Œ ë²ˆí˜¸: {ARS_ID}<br/>ë…¸ì„ : {ë…¸ì„ }",
                "style": {"backgroundColor": "white", "color": "black"}
            }
            st.pydeck_chart(pdk.Deck(
                layers=[point_layer, text_layer],
                initial_view_state=view_state,
                tooltip=tooltip
            ))

    # (2) ê¸°ì‚¬ ì˜ì—­ (placeholder)
    st.subheader("ì§‘íšŒ/ì‹œìœ„ ê´€ë ¨ ê¸°ì‚¬ ë³´ê¸°")
    st.caption("â€» í¬ë¡¤ë§ ì—°ë™ ì˜ˆì •. ë°ì´í„° ì¤€ë¹„ë˜ë©´ ì´ ì˜ì—­ì— ë…¸ì¶œë©ë‹ˆë‹¤.")
    st.empty()

    # (2.5) ê±´ì˜ì‚¬í•­ í‚¤ì›Œë“œ ìš”ì•½ (ì›Œë“œí´ë¼ìš°ë“œ + Top N + ì˜ˆì‹œ)
    st.subheader("ê±´ì˜ì‚¬í•­ í‚¤ì›Œë“œ ìš”ì•½")
    fb_all = load_feedback("data/feedback.csv")
    if fb_all.empty:
        st.caption("ì•„ì§ ì €ì¥ëœ ê±´ì˜ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        colA, colB = st.columns([1,1])
        with colA:
            only_today = st.toggle("ì´ ë‚ ì§œë§Œ ë³´ê¸°", value=True, key="wc_today")
            use_bigrams = st.toggle("ì—°ê²°ì–´(2ë‹¨ì–´)ë¡œ ë³´ê¸°", value=False, key="wc_bigram")
            img = build_wordcloud_image(
                fb_all,
                date_filter=d if only_today else None,
                use_bigrams=use_bigrams,
                font_path="data/Nanum_Gothic/NanumGothic-Regular.ttf"
            )
            if img is not None:
                st.image(img, use_container_width=True)
            else:
                st.caption("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        with colB:
            top_df = top_terms_from_feedback(
                fb_all,
                date_filter=d if only_today else None,
                use_bigrams=use_bigrams,
                top_k=20
            )
            if top_df.empty:
                st.caption("í‘œì‹œí•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown("**ìƒìœ„ í‚¤ì›Œë“œ/í‘œí˜„ TOP 20**")
                chart = (
                    alt.Chart(top_df)
                    .mark_bar()
                    .encode(
                        x=alt.X("count:Q", title="ê±´ìˆ˜"),
                        y=alt.Y("term:N", sort="-x", title=None),
                        tooltip=[alt.Tooltip("term:N", title="ìš©ì–´"),
                                 alt.Tooltip("count:Q", title="ê±´ìˆ˜"),
                                 alt.Tooltip("pct:Q", title="ë¹„ìœ¨(%)")]
                    )
                    .properties(height=420)
                )
                st.altair_chart(chart, use_container_width=True)

                sel = st.selectbox("ì˜ˆì‹œ ë¬¸ì¥ ë³´ê¸°: í‚¤ì›Œë“œ ì„ íƒ", ["ì„ íƒ ì•ˆ í•¨"] + top_df["term"].tolist())
                if sel != "ì„ íƒ ì•ˆ í•¨":
                    _df = fb_all.copy()
                    if only_today and "date" in _df.columns:
                        _df = _df[_df["date"].astype(str) == str(d)]
                    ex = _df[_df["feedback"].str.contains(re.escape(sel), case=False, na=False)] \
                        .tail(5)["feedback"]
                    if ex.empty:
                        st.caption("í•´ë‹¹ í‚¤ì›Œë“œì˜ ì˜ˆì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.markdown("**ìµœê·¼ ì˜ˆì‹œ 5ê±´**")
                        for i, line in enumerate(ex, 1):
                            st.write(f"{i}. {line}")

    # (3) ê±´ì˜ì‚¬í•­ ì…ë ¥
    st.subheader("ì˜¤ëŠ˜ì˜ ì§‘íšŒ/ì‹œìœ„ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ê±´ì˜ì‚¬í•­ì„ ë‚¨ê²¨ì£¼ì„¸ìš”")
    fb = st.text_area("ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš” (ê´€ë¦¬ìì—ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤)", height=140, key="fb_detail")
    if st.button("ë“±ë¡"):
        if not fb.strip():
            st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            save_path = Path("data/feedback.csv")
            save_path.parent.mkdir(parents=True, exist_ok=True)
            row_dict = {
                "saved_at": datetime.now().isoformat(timespec="seconds"),
                "date": str(d),
                "start": row["_start"],
                "end": row["_end"],
                "location": row["_loc"],
                "district": row["_dist"],
                "reported_head": row["_head"],
                "memo": row["_memo"],
                "feedback": fb.strip(),
            }
            if save_path.exists():
                prev = pd.read_csv(save_path)
                new  = pd.concat([prev, pd.DataFrame([row_dict])], ignore_index=True)
            else:
                new = pd.DataFrame([row_dict])
            new.to_csv(save_path, index=False, encoding="utf-8-sig")
            st.success("ê±´ì˜ì‚¬í•­ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
            st.query_params.clear()

# ===================== ë©”ì¸/ë¼ìš°íŒ… =====================
st.markdown("<div class='app-header'>ì§‘íšŒ/ì‹œìœ„ ì•Œë¦¼ ì„œë¹„ìŠ¤</div>", unsafe_allow_html=True)

# ì¢Œ/ìš° ë†’ì´ ë™ê¸°í™”
CALENDAR_H = 520
HEADER_OFFSET = 85
PANEL_BODY_H = CALENDAR_H - HEADER_OFFSET   # ì˜¤ë¥¸ìª½ ìŠ¤í¬ë¡¤ ì˜ì—­ ë†’ì´

# ë°ì´í„° ê²½ë¡œ
DATA_PATH = st.sidebar.text_input(
    "ì§‘íšŒ ë°ì´í„° ê²½ë¡œ (xlsx/csv)",
    value="data/protest_data.xlsx"
)
BUS_PATH = st.sidebar.text_input(
    "ë²„ìŠ¤ ìš°íšŒ ë°ì´í„° ê²½ë¡œ (xlsx)",
    value="data/bus_data.xlsx"
)
ROUTES_PATH = st.sidebar.text_input(
    "ë²„ìŠ¤ ë…¸ì„  ë°ì´í„° ê²½ë¡œ (CSV: routes_final.csv)",
    value="/Users/byun-yewon/KT_project/routes_final.csv"
)

# ë°ì´í„° ë¡œë“œ
try:
    df = load_events(DATA_PATH)
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
    st.stop()
bus_df = load_bus(BUS_PATH)
routes_df = load_routes(ROUTES_PATH)

# ---- ë¼ìš°íŒ…: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°(detail ëª¨ë“œ) ----
qp = st.query_params
view = qp.get("view", "")
if view == "detail":
    d_str = qp.get("date", "")
    idx_str = qp.get("idx", "0")
    try:
        d_sel = parser.parse(d_str).date()
        idx_sel = int(idx_str)
        render_detail(df, bus_df, routes_df, d_sel, idx_sel)
        st.stop()
    except Exception:
        st.warning("ì˜ëª»ëœ ë§í¬ì…ë‹ˆë‹¤. ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")
        st.query_params.clear()

# ---------- ë©”ì¸ í™”ë©´ ----------
st.markdown("### ì´ë‹¬ì˜ ì§‘íšŒ")
st.caption("ì´ë²ˆ ë‹¬ì˜ ì§‘íšŒë¥¼ í•œëˆˆì— í™•ì¸í•´ë³´ì„¸ìš”.")

left, right = st.columns(2)

# ì™¼ìª½: ìº˜ë¦°ë”
with left:
    with st.container(border=True):
        events = df_to_month_dots(df)
        options = {
            "initialView": "dayGridMonth",
            "locale": "ko",
            "height": CALENDAR_H,
            "firstDay": 0,
            "headerToolbar": {"left":"prev,next today", "center":"title", "right":""},
            "dayMaxEventRows": True,
        }
        calendar(events=events, options=options)

# ì˜¤ë¥¸ìª½: ë‚ ì§œ ë„¤ë¹„ + ì¹´ë“œ ëª©ë¡(HTML ë§í¬, ê³ ì • ë†’ì´ ì»¨í…Œì´ë„ˆ)
if "sel_date" not in st.session_state:
    st.session_state.sel_date = date.today()

with right:
    with st.container(border=True):
        nav1, nav2, nav3, nav4 = st.columns([1, 2.2, 1, 1])
        with nav1:
            if st.button("â—€", use_container_width=True):
                d = st.session_state.sel_date
                st.session_state.sel_date = d.fromordinal(d.toordinal() - 1)
        with nav2:
            dnew = st.date_input("ë‚ ì§œ ì„ íƒ", value=st.session_state.sel_date, label_visibility="collapsed")
            if dnew != st.session_state.sel_date:
                st.session_state.sel_date = dnew
        with nav3:
            if st.button("ì˜¤ëŠ˜", use_container_width=True):
                st.session_state.sel_date = date.today()
        with nav4:
            if st.button("â–¶", use_container_width=True):
                d = st.session_state.sel_date
                st.session_state.sel_date = d.fromordinal(d.toordinal() + 1)

        sel_date = st.session_state.sel_date
        WEEK_KO = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]
        st.markdown(f"#### {sel_date.month}ì›” {sel_date.day}ì¼({WEEK_KO[sel_date.weekday()]}) ì§‘íšŒ ì¼ì • ì•ˆë‚´")

        day_df = filter_by_day(df, sel_date)

        # ê³µë°± ì—†ì´ ìŠ¤í¬ë¡¤ ì»¨í…Œì´ë„ˆì— ì¹´ë“œ HTMLì„ ì¼ê´„ ì‚½ì…
        html = [f"<div style='height:{PANEL_BODY_H}px; overflow-y:auto; padding-right:8px;'>"]

        if len(day_df) == 0:
            html.append('<div class="sub">ë“±ë¡ëœ ì§‘íšŒê°€ ì—†ìŠµë‹ˆë‹¤.</div>')
        else:
            for i, (_, r) in enumerate(day_df.iterrows()):
                # ì¥ì†Œ(ê´€í• ì„œ ìˆìœ¼ë©´ ì ‘ë‘)
                loc_line = r["_loc"]
                if r["_dist"] and str(r["_dist"]).strip() not in ["nan", "None", ""]:
                    loc_line = f"{r['_dist']}  {loc_line}"

                # ë©”íƒ€(ì‹ ê³  ì¸ì›, ë©”ëª¨)
                metas = []
                if pd.notna(r["_head"]) and str(r["_head"]).strip() != "":
                    try:
                        metas.append(f"ì‹ ê³  ì¸ì› {int(r['_head'])}ëª…")
                    except:
                        metas.append(f"ì‹ ê³  ì¸ì› {r['_head']}ëª…")
                if r["_memo"] and str(r["_memo"]).strip() not in ["nan", "None", ""]:
                    metas.append(str(r["_memo"]))
                meta_text = " Â· ".join(metas)
                meta_html = f"<div class='meta'>{meta_text}</div>" if meta_text else ""

                href = f"?view=detail&date={sel_date.isoformat()}&idx={i}"

                html.append(textwrap.dedent(f"""
                    <a class="card-link" href="{href}">
                      <div class="card">
                        <div class="time">{r["_start"]} ~ {r["_end"]}</div>
                        <div class="sub">{loc_line}</div>
                        {meta_html}
                      </div>
                    </a>
                """).strip())

        html.append("</div>")
        st.markdown("\n".join(html), unsafe_allow_html=True)
